{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Copia de 4-Modules.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6Xlh7bAjr0a5",
        "YwRwi48zr0bI"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DrAlexSanz/amld-pytorch-workshop/blob/master/ALEX_4_Modules.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMlGCssRr0VA",
        "colab_type": "text"
      },
      "source": [
        "<div>\n",
        "<img src=\"https://discuss.pytorch.org/uploads/default/original/2X/3/35226d9fbc661ced1c5d17e374638389178c3176.png\" width=\"400\" style=\"margin: 50px auto; display: block; position: relative; left: -30px;\" />\n",
        "</div>\n",
        "\n",
        "<!--NAVIGATION-->\n",
        "# < [Optimization](3-Optimization.ipynb) | Modules | [CNN](5-CNN.ipynb) >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iCIOFP6r0VH",
        "colab_type": "text"
      },
      "source": [
        "### PyTorch Modules\n",
        "\n",
        "Modules are a way to build re-usable model components and to manage model parameters.\n",
        "PyTorch has many built-in modules for common operations like convolutions, recurrent neural networks, max pooling, common activation functions, etc.\n",
        "You can also build your own modules.\n",
        "\n",
        "This notenook introduces modules, and you will build a small neural network to perform image classification on MNIST.\n",
        "\n",
        "### Table of Contents\n",
        "#### 1. [Modules](#Modules)\n",
        "#### 2. [Building and Training a Neural Network](#Building-and-Training-a-Neural-Network)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIbPTuivr0VL",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "# Modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63rOu_H2r0VP",
        "colab_type": "text"
      },
      "source": [
        "### Modules manage parameters\n",
        "\n",
        "They help to\n",
        "- keep track of the parameters in your model.\n",
        "- save/load of your model.\n",
        "- reset gradients (with `model.zero_grad()`)\n",
        "- move all parameters to the gpu (with `model.cuda()`)\n",
        "\n",
        "The model parameter's are represented by `torch.nn.Parameter` objects.\n",
        "A `Parameter` is a tensor with `requires_grad` set to `True` by default, and which is automatically added to the list of parameters when used within a model. If you are interested, you can have a look at the [torch.nn.Parameter documentation](https://pytorch.org/docs/stable/_modules/torch/nn/parameter.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uBnlDE9r0VT",
        "colab_type": "text"
      },
      "source": [
        "As an example, a `Conv1d` module has two parameters: `weight` as `bias`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boS7SsDyr0VX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make sure this is running on GPU\n",
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl3MHl6Mr0Vl",
        "colab_type": "code",
        "outputId": "38d1ed18-ad0d-4a99-a2d6-7996aef6fe5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "module = torch.nn.Conv1d(5, 2, 3)\n",
        "print(module.weight) #random initialization\n",
        "print(module.bias)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[ 0.0328, -0.0854, -0.1825],\n",
            "         [-0.1952, -0.1976,  0.1778],\n",
            "         [-0.1514,  0.0381, -0.1661],\n",
            "         [ 0.1107,  0.1019, -0.1186],\n",
            "         [-0.1570,  0.0415, -0.1632]],\n",
            "\n",
            "        [[ 0.2302,  0.1127, -0.0985],\n",
            "         [-0.1735,  0.2415,  0.0937],\n",
            "         [-0.0212,  0.1650,  0.1832],\n",
            "         [-0.2357,  0.2046,  0.0326],\n",
            "         [-0.0951, -0.0981, -0.0259]]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0897, -0.1828], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1K569T4r0WB",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## Basic usage\n",
        "\n",
        "Each instance of a model has its own __parameters__.\n",
        "The parameters are initialized randomly when the model is instantiated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QMCZ9aUr0WE",
        "colab_type": "code",
        "outputId": "5955c547-fc82-49a4-ead8-607addc24dc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "linear_regression_model = torch.nn.Linear(5, 2)  # 5 input dimensions, 2 output dimensions\n",
        "\n",
        "print(\"linear_regression_model.weight = \", linear_regression_model.weight)  # running this cell more than once, you'll see different outputs\n",
        "print(\"linear_regression_model.bias = \", linear_regression_model.bias)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "linear_regression_model.weight =  Parameter containing:\n",
            "tensor([[-0.2837,  0.0623, -0.0359, -0.1244, -0.1245],\n",
            "        [-0.0004,  0.1913,  0.3049,  0.3231,  0.2751]], requires_grad=True)\n",
            "linear_regression_model.bias =  Parameter containing:\n",
            "tensor([-0.1215,  0.2536], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akohmPbvr0Wj",
        "colab_type": "text"
      },
      "source": [
        "Models operate on __batches__ of data. If a model is designed to operate on datapoints with 5 features, the shape of the model's inputs will be `(batch, 5)`. This allows us to process multiple datapoints in parallel and increase efficiency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51S28iuZr0Wm",
        "colab_type": "code",
        "outputId": "fbd7a932-f12b-4e97-ae1d-10682b2fd4a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "batch_size = 3\n",
        "x = torch.randn(batch_size, 5)\n",
        "y = torch.randn(batch_size, 2)\n",
        "\n",
        "print(\"x = {}\\ny = {}\".format(x, y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x = tensor([[ 0.9772, -0.7332,  1.0791, -0.0545, -0.4261],\n",
            "        [-1.1307,  1.5163,  0.4349,  0.4142, -0.8613],\n",
            "        [-0.7312,  1.0524, -0.5858,  1.1390,  0.2443]])\n",
            "y = tensor([[-0.0800,  1.3892],\n",
            "        [-0.9156, -0.4443],\n",
            "        [-0.6124,  0.1666]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1jLa_4Wr0W6",
        "colab_type": "text"
      },
      "source": [
        "You can __call__ the model on an input (forward pass). This evaluation uses the current model parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbiZjLDir0XO",
        "colab_type": "code",
        "outputId": "0f2e2810-6474-401d-dc2a-be55e162ed50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "predicted_y = linear_regression_model(x)\n",
        "print(\"predicted y = {}\".format(predicted_y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted y = tensor([[-4.2333e-01,  3.0720e-01],\n",
            "        [ 3.3386e-01,  5.7355e-01],\n",
            "        [ 4.0407e-04,  7.1180e-01]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJfDoaQIr0XW",
        "colab_type": "text"
      },
      "source": [
        "To optimize the model, you compute a __measure of error__ (loss) on the predictions. In this case, we use a squared error:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHL__C0Ar0XY",
        "colab_type": "code",
        "outputId": "7054806f-9792-491d-8f47-e56b80d732d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Compute a loss\n",
        "loss = torch.sum((y - predicted_y)**2)\n",
        "loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.5584, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xaSo5y6r0Xf",
        "colab_type": "text"
      },
      "source": [
        "With the loss computed, we compute __gradients__ of the loss with respect to all model parameters using automatic differentiation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSlabNZrr0Xi",
        "colab_type": "code",
        "outputId": "2a90dca2-78b5-44e4-8db9-9a4eb1c6c1d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "linear_regression_model.zero_grad()  # clear previous gradient\n",
        "loss.backward()\n",
        "\n",
        "print(\"\\nGradients:\")\n",
        "print(linear_regression_model.weight.grad)\n",
        "print(linear_regression_model.bias.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Gradients:\n",
            "tensor([[-4.3928,  5.5825, -0.3721,  2.4683, -1.5603],\n",
            "        [-5.2136,  5.8209, -2.0884,  2.2029, -0.5648]])\n",
            "tensor([3.0377, 0.9620])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcJWCyIhr0Xv",
        "colab_type": "text"
      },
      "source": [
        "You can now use these gradients to optimize the model parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErMPJ8WTr0Xy",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## Composing modules with `torch.nn.Sequential`\n",
        "\n",
        "If the model you want to build is a simple chain of other modules, you can compose them using `torch.nn.Sequential`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK2bWHzlr0X2",
        "colab_type": "code",
        "outputId": "6f77e69d-249b-49c0-aed0-b69fbc07bf65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "neural_net = torch.nn.Sequential(\n",
        "    torch.nn.Linear(5, 10),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(10, 2), # The , is optional. It won't crash like in SQL. If you want to extend the model later, this is useful.\n",
        ")\n",
        "\n",
        "# Run the model:\n",
        "neural_net(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.5343, -0.0834],\n",
              "        [-0.0378,  0.1186],\n",
              "        [-0.1188,  0.2375]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9moy4_6Cr0YC",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## Module parameters\n",
        "\n",
        "You can inspect your network's parameters using `.parameters()` or `.named_parameters()`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFh7J5ymr0YE",
        "colab_type": "code",
        "outputId": "7ce1c9bd-5442-4094-97af-3d5b6eeb0dc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "for param, tensor in neural_net.named_parameters():\n",
        "    print(\"{:10s} shape = {}\".format(param, tensor.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.weight   shape = torch.Size([10, 5])\n",
            "0.bias     shape = torch.Size([10])\n",
            "2.weight   shape = torch.Size([2, 10])\n",
            "2.bias     shape = torch.Size([2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouWcjmNXr0YK",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## Custom modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aln09Vx2r0YL",
        "colab_type": "text"
      },
      "source": [
        "A module has to implement two functions:\n",
        "\n",
        "- the `__init__` function, where you define all the sub-components that have learnable parameters. This makes sure that your module becomes aware all its parameters. The sub-components (layers) do not need to be defined in order of execution or connceted together. Don't forget to initialize the parent class `torch.nn.Module` with `super().__init__()`.\n",
        "\n",
        "\n",
        "- the `forward` function, which is the method that defines what has to be executed during the forward pass and especially how the layers are connected. This is where you call the layers that you defined inside `__init__`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TD2hdMGfr0YM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is the most basic form of a custom module:\n",
        "class MySuperSimpleModule(torch.nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Define sub-modules or parameters\n",
        "        # torch.nn.Module takes care of adding their parameters to your new module\n",
        "        self.linear = torch.nn.Linear(input_size, num_classes)\n",
        "    \n",
        "    def forward(self, x): #These two are needed.\n",
        "        out = self.linear(x)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaNLBzqRr0YV",
        "colab_type": "text"
      },
      "source": [
        "You can use the `print` function to list a model's submodules and parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAeZdNLrr0YX",
        "colab_type": "code",
        "outputId": "e1ad05bf-9c83-47aa-adc7-c3577d716ca5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "model = MySuperSimpleModule(input_size=20, num_classes=5)\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MySuperSimpleModule(\n",
            "  (linear): Linear(in_features=20, out_features=5, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgG13D0ar0Yc",
        "colab_type": "text"
      },
      "source": [
        "You can use `model.parameters()` to get the list of parameters of your model automatically inferred by PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZff22Zzr0Ye",
        "colab_type": "code",
        "outputId": "0f675db0-a45d-49cc-fa3a-223998fc1263",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "for name, p in model.named_parameters():  # Here we use a sligtly different version of the parameters() function\n",
        "    print(name, \":\\n\", p)                 # which also returns the parameter name"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "linear.weight :\n",
            " Parameter containing:\n",
            "tensor([[-0.0339,  0.0616, -0.0102,  0.1404,  0.2123,  0.1069, -0.0468,  0.0873,\n",
            "          0.1521,  0.0496,  0.1148, -0.1302,  0.0315, -0.0673, -0.1780, -0.0301,\n",
            "          0.0703,  0.0244,  0.1917,  0.0235],\n",
            "        [ 0.0496,  0.1263, -0.1431, -0.1375, -0.0589,  0.1459,  0.0760,  0.0717,\n",
            "          0.1501,  0.1005,  0.1397,  0.0534, -0.0864,  0.1364, -0.1107, -0.1217,\n",
            "         -0.0492,  0.0180, -0.1981, -0.2120],\n",
            "        [ 0.0766, -0.0974, -0.0920, -0.1333,  0.0665,  0.0966, -0.0240,  0.1874,\n",
            "         -0.0932, -0.0586,  0.1153, -0.1707, -0.0402,  0.0301, -0.0453, -0.0171,\n",
            "          0.1985,  0.1682,  0.2142,  0.1121],\n",
            "        [-0.0140,  0.1014, -0.1256, -0.1036, -0.0901,  0.0255, -0.0321,  0.0079,\n",
            "         -0.1476, -0.1572, -0.0560, -0.0167, -0.1970,  0.0030,  0.2223,  0.0269,\n",
            "          0.1609,  0.1288, -0.1994,  0.1463],\n",
            "        [ 0.0913, -0.0192, -0.1541, -0.0443,  0.1649,  0.0152, -0.2054,  0.1121,\n",
            "          0.1721, -0.0384, -0.0682,  0.0942, -0.1987, -0.0493,  0.1551,  0.0481,\n",
            "          0.1981,  0.1198,  0.0064,  0.1422]], requires_grad=True)\n",
            "linear.bias :\n",
            " Parameter containing:\n",
            "tensor([ 0.1362,  0.0177,  0.0301, -0.1854, -0.2227], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtK8EpC4r0Yp",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "# Building and Training a Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpIO6ElWr0Yr",
        "colab_type": "text"
      },
      "source": [
        "It's time to implement a neural network now. In this section, you will learn to classify handwritten digits from the widely known MNIST dataset.\n",
        "The dataset consists of 60,000 training images of size 28x28, and another 10,000 images for evaluating the quality of the trained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhqbpxzfr0Ys",
        "colab_type": "text"
      },
      "source": [
        "![MNIST](https://github.com/theevann/amld-pytorch-workshop/blob/master/figures/mnist.jpeg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOHdiREIr0Yv",
        "colab_type": "text"
      },
      "source": [
        "## Loading the dataset\n",
        "\n",
        "MNIST is widely used and a dataset and it is available in the `torchvision` library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qMoShkwr0Yx",
        "colab_type": "code",
        "outputId": "d3a2c4d1-5358-4cf3-8475-1df6d5686c14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "import torchvision\n",
        "\n",
        "# MNIST Dataset (Images and Labels)\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        "    download=True\n",
        ")\n",
        "test_dataset = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    transform=torchvision.transforms.ToTensor()\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:06, 1642405.41it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 130092.38it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2121477.17it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 48610.76it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvqenv31r0Y5",
        "colab_type": "text"
      },
      "source": [
        "A dataset in PyTorch behalves _like an array_. It has a length, and you can access its entries with `dataset[i]`.\n",
        "\n",
        "__Exercise__<br>\n",
        "Verify how many images there are in the training dataset. How is one training example represented? What is the type and shape of an entry from the dataset?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG0aKY-2r0Y8",
        "colab_type": "code",
        "outputId": "5f73d47a-9db8-47cd-9c7c-334de54fb38d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#print(len(train_dataset))\n",
        "print(train_dataset) #Easier than expected\n",
        "#train_dataset[0] will print the values of the pixels\n",
        "train_dataset[0][0].shape #It's black and white, 1, m, n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: ./data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWiW1Huzr0ZB",
        "colab_type": "text"
      },
      "source": [
        "When we train a model, we make multiple passes through all the examples in the training set. Each pass, the data points are shuffled and batched together. For this purpose, we use a `DataLoader`. The `DataLoader` support multi-threading to optize your data-loading pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q5nEsROr0ZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataset Loader (Input Batcher)\n",
        "batch_size = 100\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)# Probably the dataset is ordered. Bad for optimization.\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnnBMPqur0ZK",
        "colab_type": "text"
      },
      "source": [
        "We can now iterate through the dataset in shuffled batches. Everytime you do this, the order will be different."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ_oWI5Cr0ZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for images, labels in train_loader: #Test that all the batches have the correct size\n",
        "    assert len(images) == batch_size\n",
        "    assert len(labels) == batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kx4jGqjr0Zj",
        "colab_type": "text"
      },
      "source": [
        "__Exercise__<br>\n",
        "Search in the documentation how to enable multi-threading in the data loaders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0HJQoASr0Zm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, num_workers = 2, shuffle=True) #Fastaa!! The Cat laptop has 6 processors, 2 threads each. Not negligible.\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, num_workers = 2, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80uQzGDHr0Zv",
        "colab_type": "text"
      },
      "source": [
        "## Defining the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdF5frDJr0Zz",
        "colab_type": "text"
      },
      "source": [
        "A fully-connected neural network consists of layers that contain a number of values (neurons) computed as linear combinations of the neurons in the layer before. The first layer contains the network's input (your features), and the last layer contains the prediction. In our case, the last layer contains 10 neurons that are trained to be large when an input image is of the corresponding digit (0, 1, 2, 3, 4, 5, 6, 7, 8, 9).\n",
        "\n",
        "The parameters of this model that are optimized (trained), are the weights that connect the neurons. These are drawn as edges in the illustration below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dhSSjCjr0Z1",
        "colab_type": "text"
      },
      "source": [
        "![](https://raw.githubusercontent.com/ledell/sldm4-h2o/master/mlp_network.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXGTNRbyr0Z8",
        "colab_type": "text"
      },
      "source": [
        "To make sure that neural networks can approximate non-linear functions, each neuron's value is transformed with some non-linear transformation function $\\sigma(\\cdot)$, often called an ‘activation function’ before being fed as input to the next layer. \n",
        "\n",
        "To be precise, the neurons $\\vec x_{i+1}$ in layer $i+1$ are computed from the neurons $\\vec x_i$ in layer $i$ as \n",
        "\n",
        "$$ \\vec x_{i+1} = \\sigma\\left(W_{i+1} \\vec x_i + \\vec b_{i+1} \\right) $$\n",
        "\n",
        "where $W_{i+1}$ encodes the network parameters between each pair of input/output neurons in layer $i+1$, and $\\vec b_{i+1}$ contains 'bias terms'. $\\sigma$ operates element-wise.\n",
        "\n",
        "A layer like that can be implemented using `torch.nn.Linear` followed by an activation function such as `torch.nn.ReLU` or `torch.nn.Sigmoid`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGOqPDN4r0aH",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "__Exercise__<br>\n",
        "Implement a multi-layer fully-connected neural network with two hidden layers and the following numbers of neurons in each layer:\n",
        "\n",
        "- Input-size: *input_size*\n",
        "- 1st hidden layer: 75\n",
        "- 2nd hidden layer: 50\n",
        "- Output layer: *num_classes*\n",
        "\n",
        "Use `ReLU`s as ‘activation functions’ in between each pair of layers, but not after the last layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YWqTRvqr0aM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F  # provides some helper functions like Relu's, Sigmoids, Tanh, etc.\n",
        "\n",
        "class MyNeuralNetwork(torch.nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(MyNeuralNetwork, self).__init__()\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.num_classes = num_classes\n",
        "        \n",
        "        self.linear_1 = torch.nn.Linear(input_size, 75)\n",
        "        self.linear_2 = torch.nn.Linear(75, 50)\n",
        "        self.linear_3 = torch.nn.Linear(50, num_classes)\n",
        "        \n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.linear_1(x))\n",
        "        out = F.relu(self.linear_2(out))\n",
        "        out = self.linear_3(out) # In pytorch usually softmax goes on the loss function. If I include it here they will overlap and I´ll get two small numbers multiplied together, then vanishing likelihoods. And that makes me cry.\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mu0Okp0dr0aS",
        "colab_type": "text"
      },
      "source": [
        "Now feed an input to your network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaLhWQU-r0aT",
        "colab_type": "code",
        "outputId": "266a4c0a-189a-49db-97f6-0ff4f3edaab2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x = torch.rand(16, 28 * 28)  # the first dimension is reserved for the 'batch_size'\n",
        "model = MyNeuralNetwork(input_size=28 * 28, num_classes=10)\n",
        "out = model(x)  # this calls model.forward(x)\n",
        "out[0, :]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0885,  0.1667, -0.0921, -0.1656, -0.0109,  0.0769,  0.0530,  0.0832,\n",
              "         0.1305, -0.1496], grad_fn=<SliceBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A47TRDCFr0ar",
        "colab_type": "text"
      },
      "source": [
        "__Exercise__ <br>\n",
        "What does `out[0, :]` above represent?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC12Qbl2r0au",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## Training the model\n",
        "\n",
        "Most of the functions to train a model follow a similar pattern in PyTorch.\n",
        "In most of the cases in consists of the following steps:\n",
        "- Loop over data (in batches)\n",
        "- Create a prediction (forward pass)\n",
        "- Clear previous gradients (!)\n",
        "- Compute gradients (backward pass)\n",
        "- Parameter update (using an optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8rYYOk7r0aw",
        "colab_type": "code",
        "outputId": "ede9f3a0-2b07-4bfc-9b9e-01e7dbc42160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Copy all model parameters to the GPU\n",
        "model = model.to(device)\n",
        "\n",
        "# Define the Loss function and Optimizer that you want to use\n",
        "criterion = torch.nn.CrossEntropyLoss()  \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)  # NOTE: model.parameters() is to tell Adam which parameters I need to optimize\n",
        "\n",
        "# Passes over the whole dataset\n",
        "for epoch in range(5):\n",
        "    total_loss = 0.0\n",
        "    \n",
        "    # Loop over batches in the training set\n",
        "    for (inputs, labels) in train_loader:\n",
        "        \n",
        "        # Move inputs from CPU memory to GPU memory\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # The pixels in our images have a square 28x28 structure, but the network\n",
        "        # accepts a *vector* of inputs. We therefore reshape it.\n",
        "        # -1 is a special number that indicates 'whatever is left'\n",
        "        inputs = inputs.view(-1, 28*28)\n",
        "\n",
        "        # Do a forward pass, loss computation, compute gradient, and optimize\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Add up training losses so we can compute an average later\n",
        "        total_loss += loss.item()\n",
        "        \n",
        "    print(\"Epoch %d, Loss=%.4f\" % (epoch+1, total_loss/len(train_loader)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss=0.4291\n",
            "Epoch 2, Loss=0.1833\n",
            "Epoch 3, Loss=0.1337\n",
            "Epoch 4, Loss=0.1051\n",
            "Epoch 5, Loss=0.0872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Xlh7bAjr0a5",
        "colab_type": "text"
      },
      "source": [
        "Note:\n",
        "- We can use the `.to` function on the model directly. Indeed, since PyTorch knows all the model parameters, it can put all the parameters on the correct device.\n",
        "- We use `model.parameters()` to get all the parameters of the model and we can instantiate an optimizer that will optimize these parameters `torch.optim.SGD(model.parameters())`.\n",
        "- To apply the forward function of the module, we write `model(input)`. In most cases, `model.forward(inputs)` would also work, but there is a slight difference : PyTorch allows you to register hook functions for a model that are automatically called when you do a forward pass on your model. Using `model(input)` will call these hooks and then call the forward function, while using `model.forward(inputs)` will just silently ignore them.\n",
        "\n",
        "Do you see the convenience of Modules?\n",
        "\n",
        "### Loss functions\n",
        "\n",
        "PyTorch comes with a lot of predefined loss functions :\n",
        "- `L1Loss`\n",
        "- `MSELoss`\n",
        "- `CrossEntropyLoss`\n",
        "- `NLLLoss`\n",
        "- `PoissonNLLLoss`\n",
        "- `KLDivLoss`\n",
        "- `BCELoss`\n",
        "- `...`\n",
        "\n",
        "Check out the [PyTorch Documentation](https://pytorch.org/docs/master/nn.html#loss-functions)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyI8C7Vor0a9",
        "colab_type": "text"
      },
      "source": [
        "### Assessing model performance \n",
        "This function loops over another `data_loader` (usually containing test/validation data) and computes the model's accuracy on it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eY1N65hr0bA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(model, data_loader, device):\n",
        "    with torch.no_grad(): # during model evaluation, we don't need the autograd mechanism (speeds things up)\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs = inputs.to(device)     \n",
        "            inputs = inputs.view(-1, 28*28)\n",
        "            \n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1) # 10 outputs, I do an argmax or a max. This is equivalent to collapsing the 10 outputs.\n",
        "            \n",
        "            correct += (predicted.cpu() == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "            \n",
        "    acc = correct / total\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOwPOIRGr0bF",
        "colab_type": "code",
        "outputId": "477f8cf4-2f9c-4f71-93f4-c5c6d7f661b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy(model, test_loader, device)  # look at: accuracy(model, train_loader, device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9687"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwRwi48zr0bI",
        "colab_type": "text"
      },
      "source": [
        "### We get an accuracy of around 97%. Can you improve this?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCFUaDgFr0bL",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## Storing and loading models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwKkykvir0bN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model, \"my_model.pt\") #Useful"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeOnoxT9r0bW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_model_loaded = torch.load(\"my_model.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ope7pkCr0bo",
        "colab_type": "code",
        "outputId": "2ac6d30f-1546-449d-bade-998f934877c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "print(model.linear_3.bias)\n",
        "print(my_model_loaded.linear_3.bias)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([-0.1436,  0.1358, -0.1001, -0.1468,  0.2077,  0.1968, -0.0029,  0.0573,\n",
            "         0.0638, -0.1277], device='cuda:0', requires_grad=True)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-0c660881804c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_model_loaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'my_model_loaded' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmMYFS5_r0bx",
        "colab_type": "text"
      },
      "source": [
        "___\n",
        "\n",
        "This intro to modules used [this medium post](https://medium.com/deeplearningbrasilia/deep-learning-introduction-to-pytorch-5bd39421c84) as a resource."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDGV4sPxr0by",
        "colab_type": "text"
      },
      "source": [
        "<!--NAVIGATION-->\n",
        "# < [Optimization](3-Optimization.ipynb) | Modules | [CNN](5-CNN.ipynb) >"
      ]
    }
  ]
}